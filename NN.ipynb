{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASS = 40\n",
    "N_SAMPLES = 10\n",
    "TOTAL_SAMPLES = 400\n",
    "TEST_PERCENTAGE = 0.2\n",
    "TEST_SAMPLES = int(TOTAL_SAMPLES * TEST_PERCENTAGE)\n",
    "TRAIN_SAMPLES = int(TOTAL_SAMPLES - TEST_SAMPLES)\n",
    "COLLECTION_FILE_NAME = 'data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def read_data(f_index):    \n",
    "    train_X = []\n",
    "    train_Y = []\n",
    "    test_X = []\n",
    "    test_Y = []\n",
    "    for img_num in range(N_SAMPLES):\n",
    "        image = np.array(Image.open(\n",
    "            f\"orl_faces/s{f_index + 1}/{img_num + 1}.pgm\").getdata())\n",
    "        if (img_num in range(N_SAMPLES)[-int(N_SAMPLES*TEST_PERCENTAGE):]):\n",
    "            test_X.append(image)\n",
    "            test_Y.append(f_index)\n",
    "        else:\n",
    "            train_X.append(image)\n",
    "            train_Y.append(f_index)\n",
    "            \n",
    "    return np.asarray(train_X), np.asarray(train_Y), np.asarray(test_X), np.asarray(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 10304) (320,) (80, 10304) (80,)\n",
      "CPU times: user 46.9 ms, sys: 219 ms, total: 266 ms\n",
      "Wall time: 587 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processes_args = ((i) for i in range(N_CLASS))\n",
    "with mp.Pool(4) as p:\n",
    "    results = p.map(read_data, processes_args)\n",
    "    \n",
    "X_train = list(x[0] for x in results)\n",
    "X_train = np.concatenate(X_train)\n",
    "Y_train = list(x[1] for x in results)\n",
    "Y_train = np.concatenate(Y_train)\n",
    "\n",
    "X_test = list(x[2] for x in results)\n",
    "X_test = np.concatenate(X_test)\n",
    "Y_test = list(x[3] for x in results)\n",
    "Y_test = np.concatenate(Y_test)\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "np.save(f\"train_{COLLECTION_FILE_NAME}_x\", X_train)\n",
    "np.save(f\"train_{COLLECTION_FILE_NAME}_y\", Y_train)\n",
    "np.save(f\"test_{COLLECTION_FILE_NAME}_x\", X_test)\n",
    "np.save(f\"test_{COLLECTION_FILE_NAME}_y\", Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 10304) (320,) (80, 10304) (80,)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset function\n",
    "\n",
    "def load_dataset():\n",
    "    train_X = np.load(f\"train_{COLLECTION_FILE_NAME}_x.npy\")\n",
    "    train_Y = np.load(f\"train_{COLLECTION_FILE_NAME}_y.npy\")\n",
    "    test_X = np.load(f\"test_{COLLECTION_FILE_NAME}_x.npy\")\n",
    "    test_Y = np.load(f\"test_{COLLECTION_FILE_NAME}_y.npy\")\n",
    "    return train_X, train_Y, test_X, test_Y\n",
    "    \n",
    "X_train, Y_train, X_test, Y_test = load_dataset() \n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale images\n",
    "\n",
    "X_train = X_train/255.\n",
    "X_test  = X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 40) (80, 40)\n"
     ]
    }
   ],
   "source": [
    "# Function for encode categorical labels\n",
    "\n",
    "def encode_labels(df_train, df_test):\n",
    "    df = np.concatenate((df_train, df_test))\n",
    "    enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    df = enc.fit_transform((df).reshape((-1, 1)))\n",
    "    return df[:-80], df[320:]\n",
    "\n",
    "Y_train_encoded, Y_test_encoded = encode_labels(Y_train, Y_test)\n",
    "print(Y_train_encoded.shape, Y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of NN with helper functions\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros((dim, 40))\n",
    "    b = 0\n",
    "\n",
    "    assert(w.shape == (dim, 40))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    m = X.shape[1]\n",
    "    A = sigmoid(np.dot(w.T, X) + b)                           # compute activation\n",
    "    cost = - np.mean(Y * np.log(A) + (1 - Y) * np.log(1 - A)) # compute cost\n",
    "    dw = np.dot(X, (A - Y).T) / m\n",
    "    db = np.mean(A - Y)\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs\n",
    "\n",
    "\n",
    "def predict(w, b, X):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    w = w.reshape(X.shape[0], 40)\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    Y_prediction = np.round(A)\n",
    "        \n",
    "    assert(Y_prediction.shape == (40, m))\n",
    "    \n",
    "    return Y_prediction\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-ee4f4e1c4c44>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-ee4f4e1c4c44>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    d = model(X_train.T, Y_train_encoded.T, X_test.T., Y_test_encoded.T, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "d = model(X_train.T, Y_train_encoded.T, X_test.T, Y_test_encoded.T, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
