{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 10304) (320,) (80, 10304) (80,)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset function\n",
    "\n",
    "def load_dataset():\n",
    "    train_X = np.load(f\"train_{COLLECTION_FILE_NAME}_x.npy\")\n",
    "    train_Y = np.load(f\"train_{COLLECTION_FILE_NAME}_y.npy\")\n",
    "    test_X = np.load(f\"test_{COLLECTION_FILE_NAME}_x.npy\")\n",
    "    test_Y = np.load(f\"test_{COLLECTION_FILE_NAME}_y.npy\")\n",
    "    return train_X, train_Y, test_X, test_Y\n",
    "    \n",
    "X_train, Y_train, X_test, Y_test = load_dataset() \n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default scaling\n",
    "\n",
    "X_train = X_train/255.\n",
    "X_test  = X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale images A\n",
    "\n",
    "X_train = X_train - np.mean(X_train)\n",
    "X_test  = X_train - np.mean(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale images B\n",
    "\n",
    "X_train = (X_train - np.mean(X_train, axis=0))/np.std(X_train, axis=0)\n",
    "X_test  = (X_test - np.mean(X_test, axis=0))/np.std(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 40) (80, 40)\n"
     ]
    }
   ],
   "source": [
    "# Function for encode categorical labels\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def encode_labels(df_train, df_test):\n",
    "    df = np.concatenate((df_train, df_test))\n",
    "    enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    df = enc.fit_transform((df).reshape((-1, 1)))\n",
    "    return df[:-80], df[320:]\n",
    "\n",
    "Y_train_encoded, Y_test_encoded = encode_labels(Y_train, Y_test)\n",
    "print(Y_train_encoded.shape, Y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 213) (80, 213)\n"
     ]
    }
   ],
   "source": [
    "# PCA REALIZATION\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(.97)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_PCA = pca.transform(X_train)\n",
    "X_test_PCA  = pca.transform(X_test)\n",
    "print(X_train_PCA.shape, X_test_PCA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of NN with helper functions\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros((dim, 40))\n",
    "    b = 0\n",
    "\n",
    "    assert(w.shape == (dim, 40))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    m = X.shape[1]\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "\n",
    "    cost = np.mean((Y - A)**2)\n",
    "\n",
    "    dw = np.dot(X, (A - Y).T) / m\n",
    "    db = np.mean(A - Y)\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs\n",
    "\n",
    "\n",
    "def predict(w, b, X):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    w = w.reshape(X.shape[0], 40)\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    Y_prediction = []\n",
    "    for i in range(A.shape[1]):\n",
    "        max_index = np.argmax(A[:, i])\n",
    "        zeros = np.zeros(A.shape[0])\n",
    "        zeros[max_index] = 1. if A[max_index][i] >= 0.5 else 0. \n",
    "        Y_prediction.append(zeros)\n",
    "    \n",
    "    Y_prediction = np.asarray(Y_prediction).T\n",
    "    \n",
    "    assert(Y_prediction.shape == (40, m))\n",
    "    \n",
    "    return Y_prediction\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.250000\n",
      "Cost after iteration 100: 0.195501\n",
      "Cost after iteration 200: 0.155882\n",
      "train accuracy: 99.6796875 %\n",
      "test accuracy: 98.3125 %\n"
     ]
    }
   ],
   "source": [
    "d = model(X_train_PCA.T, Y_train_encoded.T, X_test_PCA.T, Y_test_encoded.T, num_iterations = 250, learning_rate = 0.005, print_cost = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
