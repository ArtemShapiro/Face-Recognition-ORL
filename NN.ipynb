{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 10304) (320,) (80, 10304) (80,)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset function\n",
    "\n",
    "def load_dataset():\n",
    "    train_X = np.load(f\"train_{COLLECTION_FILE_NAME}_x.npy\")\n",
    "    train_Y = np.load(f\"train_{COLLECTION_FILE_NAME}_y.npy\")\n",
    "    test_X = np.load(f\"test_{COLLECTION_FILE_NAME}_x.npy\")\n",
    "    test_Y = np.load(f\"test_{COLLECTION_FILE_NAME}_y.npy\")\n",
    "    return train_X, train_Y, test_X, test_Y\n",
    "    \n",
    "X_train, Y_train, X_test, Y_test = load_dataset() \n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 10304) (320,)\n"
     ]
    }
   ],
   "source": [
    "# Extra shuffle for samples\n",
    "def shuffle_samples(x, y):\n",
    "    data = np.concatenate((x, y.reshape(-1,1)), axis=1)\n",
    "    np.random.shuffle(data)\n",
    "    return data[:,:-1] , data[:,-1]\n",
    "\n",
    "X_train, Y_train = shuffle_samples(X_train, Y_train)\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default scaling\n",
    "def minmaxscaler(samples):\n",
    "    return samples/255.\n",
    "\n",
    "# Scale images A\n",
    "def scale_by_mean(samples):\n",
    "    return samples - np.mean(samples)\n",
    "\n",
    "# Scale images B\n",
    "def scale_by_feature(samples):\n",
    "    return (samples - np.mean(samples, axis=0))/np.std(samples, axis=0)\n",
    "\n",
    "X_train = minmaxscaler(X_train)\n",
    "X_test  = minmaxscaler(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 40) (80, 40)\n"
     ]
    }
   ],
   "source": [
    "# Function for encode categorical labels\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def encode_labels(df_train, df_test):\n",
    "    df = np.concatenate((df_train, df_test))\n",
    "    enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    df = enc.fit_transform((df).reshape((-1, 1)))\n",
    "    return df[:-80], df[320:]\n",
    "\n",
    "Y_train_encoded, Y_test_encoded = encode_labels(Y_train, Y_test)\n",
    "print(Y_train_encoded.shape, Y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 202) (80, 202)\n"
     ]
    }
   ],
   "source": [
    "# PCA REALIZATION\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def vector_by_pca(train, test):\n",
    "    pca = PCA(.97)\n",
    "    pca.fit(train)\n",
    "    return pca.transform(train), pca.transform(test)\n",
    "\n",
    "X_train_PCA, X_test_PCA = vector_by_pca(X_train, X_test)\n",
    "print(X_train_PCA.shape, X_test_PCA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of NN with helper functions\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros((dim, 40))\n",
    "    b = 0\n",
    "\n",
    "    assert(w.shape == (dim, 40))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "def count_loss(w, b, X, Y):\n",
    "    m = X.shape[1]\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    cost = -np.mean(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
    "    return cost, m, A\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    cost, m, A = count_loss(w, b, X, Y)\n",
    "\n",
    "    dw = np.dot(X, (A - Y).T) / m\n",
    "    db = np.mean(A - Y)\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, X_test, Y_test, print_cost = False):\n",
    "    train_costs = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        valid_loss, _, _ = count_loss(w, b, X_test, Y_test)\n",
    "\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            train_costs.append(cost)\n",
    "\n",
    "        if print_cost and i % 10 == 0:\n",
    "            print (\"Train cost after iteration %i: %f\" %(i, cost))\n",
    "            print (\"Test cost after iteration %i: %f\" %(i, valid_loss))\n",
    "            \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, train_costs\n",
    "\n",
    "\n",
    "def predict(w, b, X):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    w = w.reshape(X.shape[0], 40)\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    Y_prediction = []\n",
    "    for i in range(A.shape[1]):\n",
    "        max_index = np.argmax(A[:, i])\n",
    "        zeros = np.zeros(A.shape[0])\n",
    "        zeros[max_index] = 1. if A[max_index][i] >= 0.5 else 0. \n",
    "        Y_prediction.append(zeros)\n",
    "    \n",
    "    Y_prediction = np.asarray(Y_prediction).T\n",
    "    \n",
    "    assert(Y_prediction.shape == (40, m))\n",
    "    \n",
    "    return Y_prediction\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, X_test, Y_test, print_cost)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "    print(\"train accuracy: {} %\".format(100 * np.mean(np.argmax(Y_prediction_train, axis=0) == np.argmax(Y_train, axis=0))))\n",
    "    print(\"test accuracy: {} %\".format(100 * np.mean(np.argmax(Y_prediction_test, axis=0) ==  np.argmax(Y_test, axis=0))))\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train cost after iteration 0: 0.693147\n",
      "Test cost after iteration 0: 0.691620\n",
      "Train cost after iteration 10: 0.678299\n",
      "Test cost after iteration 10: 0.677491\n",
      "Train cost after iteration 20: 0.664972\n",
      "Test cost after iteration 20: 0.664699\n",
      "Train cost after iteration 30: 0.652515\n",
      "Test cost after iteration 30: 0.652695\n",
      "Train cost after iteration 40: 0.640654\n",
      "Test cost after iteration 40: 0.641244\n",
      "Train cost after iteration 50: 0.629261\n",
      "Test cost after iteration 50: 0.630230\n",
      "Train cost after iteration 60: 0.618265\n",
      "Test cost after iteration 60: 0.619589\n",
      "Train cost after iteration 70: 0.607624\n",
      "Test cost after iteration 70: 0.609282\n",
      "Train cost after iteration 80: 0.597307\n",
      "Test cost after iteration 80: 0.599282\n",
      "Train cost after iteration 90: 0.587291\n",
      "Test cost after iteration 90: 0.589566\n",
      "train accuracy: 98.75 %\n",
      "test accuracy: 90.0 %\n"
     ]
    }
   ],
   "source": [
    "d = model(X_train_PCA.T, Y_train_encoded.T, X_test_PCA.T, Y_test_encoded.T, num_iterations = 100, learning_rate = 0.005,print_cost= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
